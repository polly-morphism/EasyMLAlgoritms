{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing\n",
    "\n",
    "def getdata(filename, q_rows, q_cols):\n",
    "    dataset = np.zeros((q_rows,q_cols))\n",
    "\n",
    "    with open(filename, \"r\") as file:\n",
    "        csv_reader = reader(file)\n",
    "        i = 0\n",
    "        if q_rows == 'all' and q_cols == 'all':\n",
    "            for row in csv_reader:\n",
    "                if i > 0:\n",
    "                    if not row:\n",
    "                        continue\n",
    "                    for j in range(len(row)):\n",
    "                        dataset[i-1, j] = float(row[j])\n",
    "                i += 1\n",
    "            return dataset\n",
    "            \n",
    "        for row in csv_reader:\n",
    "            if i > 0:\n",
    "                if not row or i == q_rows+1:\n",
    "                    continue\n",
    "                for j in range(q_rows):\n",
    "                    dataset[i-1, j] = float(row[j])\n",
    "            i += 1\n",
    "    return dataset\n",
    "\n",
    "class NormStandart():\n",
    "    def __init__(self, dataset, dsformat):\n",
    "        self.dataset = dataset\n",
    "        self.format = dsformat\n",
    "\n",
    "    def normalize(self, dataset):\n",
    "        max = dataset.max()\n",
    "        min = dataset.min()\n",
    "        for i in range(len(dataset.transpose()[0])):\n",
    "            for j in range(4):\n",
    "                dataset[i][j] = (dataset[i][j] - min)/(max-min)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    def mean(self, dataset):\n",
    "        col_quant = len(dataset[0])\n",
    "        dataset = dataset.transpose()\n",
    "        means = np.zeros(col_quant)\n",
    "        for i in range(col_quant):\n",
    "            means[i] = np.sum(dataset[i])/float(len(dataset[i]))\n",
    "        return means\n",
    "\n",
    "    # calculate column standard deviations\n",
    "    def stdev(self, dataset, means):\n",
    "        col_quant = len(dataset[0])\n",
    "        stdevs = np.zeros(col_quant)\n",
    "        for i in range(col_quant):\n",
    "            variance = [pow(row[i]-means[i], 2) for row in dataset]\n",
    "            stdevs[i] = sum(variance)\n",
    "        stdevs = [sqrt(x/(float(len(dataset)-1))) for x in stdevs]\n",
    "        return np.array(stdevs)\n",
    "\n",
    "    def standardize_dataset(self, dataset, means, stdevs):\n",
    "        for row in dataset:\n",
    "            for i in range(len(row)):\n",
    "                row[i] = (row[i] - means[i]) / stdevs[i]\n",
    "\n",
    "    def normalize_and_standartize(self):\n",
    "\n",
    "        self.dataset = self.normalize(self.dataset)\n",
    "        means = self.mean(self.dataset)\n",
    "        stdevs = self.stdev(self.dataset, means)\n",
    "\n",
    "        for row in self.dataset:\n",
    "            for i in range(len(row)):\n",
    "                row[i] = (row[i] - means[i]) / stdevs[i]\n",
    "        if self.format == \"numpy\":\n",
    "            return self.dataset\n",
    "        elif self.format == \"pandas\":\n",
    "            return pd.DataFrame(data=self.dataset)\n",
    "\n",
    "ds = getdata(\"winequality-white.csv\", 'all', 'all')\n",
    "ns = NormStandart(ds, \"numpy\")\n",
    "dataset_nolabels = ns.normalize_and_standartize()\n",
    "i = 0\n",
    "dataset = np.zeros((100,5))\n",
    "for i in range(100):\n",
    "    if i <= 49:\n",
    "        dataset[i] = np.append(dataset_nolabels[i], 1, axis=None)\n",
    "    else:\n",
    "        dataset[i] = np.append(dataset_nolabels[i], -1, axis=None)\n",
    "\n",
    "dataset = pd.DataFrame(data=dataset)\n",
    "\n",
    "Y = dataset.loc[:, 4]\n",
    "X = dataset.iloc[:, :-1]\n",
    "\n",
    "# # insert 1 in every row for intercept b\n",
    "X.insert(loc=len(X.columns), column=4, value=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train Data\")\n",
    "print(X_train.head(5))\n",
    "print(y_train.head(5))\n",
    "\n",
    "print(\"Test Data\")\n",
    "print(X_test.head(5))\n",
    "print(y_test.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate root mean squared error\n",
    "def rmse_metric(actual, predicted):\n",
    "\tsum_error = 0.0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tprediction_error = predicted[i] - actual[i]\n",
    "\t\tsum_error += (prediction_error ** 2)\n",
    "\tmean_error = sum_error / float(len(actual))\n",
    "\treturn sqrt(mean_error)\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\trmse = rmse_metric(actual, predicted)\n",
    "\t\tscores.append(rmse)\n",
    "\treturn scores\n",
    "\n",
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "\tyhat = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tyhat += coefficients[i + 1] * row[i]\n",
    "\treturn yhat\n",
    "\n",
    "# Estimate linear regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tfor row in train:\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "\t\t\terror = yhat - row[-1]\n",
    "\t\t\tcoef[0] = coef[0] - l_rate * error\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
    "\t\t\t# print(l_rate, n_epoch, error)\n",
    "\treturn coef\n",
    "\n",
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "def linear_regression_sgd(train, test, l_rate, n_epoch):\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "\tfor row in test:\n",
    "\t\tyhat = predict(row, coef)\n",
    "\t\tpredictions.append(yhat)\n",
    "\treturn(predictions)\n",
    "\n",
    "# Linear Regression on wine quality dataset\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'winequality-white.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.01\n",
    "n_epoch = 50\n",
    "scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
